#####For Live Session: Part 1 (3-5 hours)
##In the last unit you used a KNN classifier to classify the passengers who survived and died.  Now we will use a Naïve Bayes (NB) classifier and compare the two! 
##Using all 891 observations, train a NB model with Age and Pclass as predictors and use this model to predict the survival of a 30 year old passenger in the 1, 2 and 3 classes.  Use the “type = raw” option to look at the predicted percentage of each outcome. (One slide.)


```{r}
library(XML) #xml_Parse
library(dplyr)
library(tidyr)
library(stringi)
library(rvest) #html_table, html_node
library(ggplot2)
library(RCurl) #getURL
library(class)
library(caret)
library(e1071)

hello1 = read.csv("titanic_train.csv")
dim(hello1)
head(hello1)
hello1 %>% ggplot(aes(x = Age, y = Pclass, color = Survived)) + geom_point()

model = naiveBayes(Survived~.,data = hello1)

#1st class
df1 = data.frame(Age = "30", Pclass = 1)
predict(model,df1) #just classifications
predict(model,df1, type = "raw") #gives probabilities 

#2st class
df2 = data.frame(Age = "30", Pclass = 2)
predict(model,df2) #just classifications
predict(model,df2, type = "raw") #gives probabilities 

#3rd class
df3 = data.frame(Age = "30", Pclass = 3)
predict(model,df3) #just classifications
predict(model,df3, type = "raw") #gives probabilities 
```
##Split the 891 observations into a training and test set 70% - 30% using this seed and code:
```{r}
titanic=hello1
titanicClean = titanic %>% filter(!is.na(Age) & !is.na(Pclass))
set.seed(4)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
dim(testTitanic)
head(testTitanic)
dim(trainTitanic)
head(trainTitanic)
```
##Train a NB model based on the training set using just the Age and Pclass variables. Use the model to predict the survival of those in the test set and use those results to evaluate the model based on accuracy, sensitivity and specificity. Finally, Compare the results to what you found with the KNN classifier. (At least one slide.)

```{r}
model2 = naiveBayes(trainTitanic[,c(3,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,6)])
head(predict(model2,testTitanic[,c(3,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived)
CM = confusionMatrix(table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived))
```
##KNN
```{r}
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))
```
##Now repeat the above with a new seed and compare the accuracy, sensitivity and specificity.  Do this 3 or 4 times to observe the variance in the statistics. (At least one slide.)
```{r}
#change seed
set.seed(5)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
#NB model
model2 = naiveBayes(trainTitanic[,c(3,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,6)])
head(predict(model2,testTitanic[,c(3,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived)
CM_NB = confusionMatrix(table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived))
#KNN
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM_KNN = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))

#change seed
set.seed(10)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
#NB model
model2 = naiveBayes(trainTitanic[,c(3,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,6)])
head(predict(model2,testTitanic[,c(3,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived)
CM_NB = confusionMatrix(table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived))
#KNN
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM_KNN = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))

#change seed
set.seed(101)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
#NB model
model2 = naiveBayes(trainTitanic[,c(3,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,6)])
head(predict(model2,testTitanic[,c(3,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived)
CM_NB = confusionMatrix(table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived))
#KNN
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM_KNN = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))
```
##Write a loop to repeat the above for 100 different values of the seed.  Find the average of the accuracy, sensitivity and specificity to get a stable (smaller variance) statistic to evaluate the model.  (At least one slide.)
```{r}
seedN=100
accuracy_NB = matrix(seedN,1)
accuracy_KNN = matrix(seedN,1)
sensitivity_NB = matrix(seedN,1)
sensitivity_KNN = matrix(seedN,1)
specificity_NB = matrix(seedN,1)
specificity_KNN = matrix(seedN,1)

 
for(i in 1:seedN)
{
#  set.seed(i)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
#NB model
model2 = naiveBayes(trainTitanic[,c(3,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,6)])
head(predict(model2,testTitanic[,c(3,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived)
CM_NB = confusionMatrix(table(predict(model2,testTitanic[,c(3,6)]),testTitanic$Survived))
accuracy_NB[i] = CM_NB$overall[1]
sensitivity_NB[i] = CM_NB$byClass[1]
specificity_NB[i] = CM_NB$byClass[2]
#KNN
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM_KNN = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))
accuracy_KNN[i] = CM_KNN$overall[1]
sensitivity_KNN[i] = CM_KNN$byClass[1]
specificity_KNN[i] = CM_KNN$byClass[2]
}
mean(accuracy_NB)
mean(accuracy_KNN)
mean(sensitivity_NB)
mean(sensitivity_KNN)
mean(specificity_NB)
mean(specificity_KNN)
```
##Now add Sex to the model so that it has Age, Pclass and Sex in the NB model.  Use the trainTitanic(set.seed(4)) dataframe to train the model and create a confusion matrix using the testTitanic dataframe.  In addition, find the Accuracy, Sensitivity and Specificity. (1 slide)
```{r}
titanic=hello1
titanicClean = titanic %>% filter(!is.na(Age) & !is.na(Pclass))
set.seed(4)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
model2 = naiveBayes(trainTitanic[,c(3,5,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,5,6)])
head(predict(model2,testTitanic[,c(3,5,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,5,6)]),testTitanic$Survived)
CM = confusionMatrix(table(predict(model2,testTitanic[,c(3,5,6)]),testTitanic$Survived))
```

##Again write a loop to get a stable estimate of the accuracy, sensitivity and specificity of this model (using 100 unique seeds).  (1 slide)
```{r}
seedN=100
accuracy_NB = matrix(seedN,1)
sensitivity_NB = matrix(seedN,1)
specificity_NB = matrix(seedN,1)

 
for(i in 1:seedN)
{
set.seed(i)
titanic=hello1
titanicClean = titanic %>% filter(!is.na(Age) & !is.na(Pclass))
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
#NB model
model2 = naiveBayes(trainTitanic[,c(3,5,6)],trainTitanic$Survived)
predict(model2,testTitanic[,c(3,5,6)])
head(predict(model2,testTitanic[,c(3,5,6)],type = "raw"))
table(predict(model2,testTitanic[,c(3,5,6)]),testTitanic$Survived)
CM_NB = confusionMatrix(table(predict(model2,testTitanic[,c(3,5,6)]),testTitanic$Survived))
accuracy_NB[i] = CM_NB$overall[1]
sensitivity_NB[i] = CM_NB$byClass[1]
specificity_NB[i] = CM_NB$byClass[2]
}
mean(accuracy_NB)
mean(sensitivity_NB)
mean(specificity_NB)
```
##BONUS: Using the Male and Female KNN from the bonus of Unit 6, combine the two confusion matrices from the Male and Female KNN models to make one confusion matrix and find the accuracy, sensitivity and specificity based on that model.  Compare this with the performance of your NB model.  Do you prefer one over the other?  
```{r}
#KNN_male
titanic=hello1
titanicClean = titanic %>% filter(!is.na(Age) & !is.na(Pclass))
set.seed(4)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
trainTitanic_male <- filter(trainTitanic,Sex == "male")
testTitanic_male <- filter(testTitanic,Sex == "male")
classifications_male = knn(trainTitanic_male[,c(3,6)],trainTitanic_male[,c(3,6)],as.factor(trainTitanic_male$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic_male$Survived),classifications_male)
CM_KNN_male = confusionMatrix(table(as.factor(trainTitanic_male$Survived),classifications_male))
CM_KNN_male
#KNN_female
trainTitanic_female <- filter(trainTitanic,Sex == "female")
testTitanic_female <- filter(testTitanic,Sex == "female")
classifications_female = knn(trainTitanic_female[,c(3,6)],trainTitanic_female[,c(3,6)],as.factor(trainTitanic_female$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic_female$Survived),classifications_female)
CM_KNN_female = confusionMatrix(table(as.factor(trainTitanic_female$Survived),classifications_female))
CM_KNN_female
```
#####For Live Session: Part 2 (1 – 3 hours)
##a. For the full (multinomial) IRIS data (the iris dataset in R), do a 70-30 train/test cross validation and use sepal length and width as predictors.  Generate 100 different train/test splits and calculate the average accuracy, sensitivity and specificity.  Compare the average accuracy to that to the KNN model you used in Unit 6.  
```{r}
# NB Loop for average of many training / test partition

iterations = 500

masterAcc = matrix(nrow = iterations)

splitPerc = .7 #Training / Test split Percentage

for(j in 1:iterations)
{
  
  trainIndices = sample(1:dim(mpg)[1],round(splitPerc * dim(mpg)[1]))
  train = mpg[trainIndices,]
  test = mpg[-trainIndices,]
  
  model = naiveBayes(train[,c(8,9)],as.factor(train$drv),laplace = 1)
  table(predict(model,test[,c(8,9)]),as.factor(test$drv))
  CM = confusionMatrix(table(predict(model,test[,c(8,9)]),as.factor(test$drv)))
  masterAcc[j] = CM$overall[1]
}

MeanAcc = colMeans(masterAcc)

MeanAcc
```
#####For Live Session: BONUS
##Use the NYT News/Other Classifier code to analyze stories about Trump last month (search term “Trump”). We would like to build a classifier that will classify between news stories and other and we would like to compare two models: one that uses the headline and one that uses the snippet.  Compare these two models based on sensitivity and specificity and provide at least one plot to help you visualize the results.  

```{r}
#NYT Example
#headline

library(tm) #text mining library provides the stopwords() function
library(tidyr)
library(plyr)
library(jsonlite)
library(dplyr)
library(tidyverse)

NYTIMES_KEY = "OG89fUubcS8FXofVrLA4dmIOHh5omiFa" #Your Key Here … get from NTY API website

# Let's set some parameters

# Trump Search
term <- "Trump" # Need to use + to string together separate words
begin_date <- "20190415"
end_date <- "20190502"

baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
                  "&begin_date=",begin_date,"&end_date=",end_date,
                  "&facet_filter=true&api-key=",NYTIMES_KEY, sep="")

baseurl

initialQuery <- jsonlite::fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages

pages <- list()
for(i in 0:maxPages){
  nytSearch <- jsonlite::fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame() 
  message("Retrieving page ", i)
  pages[[i+1]] <- nytSearch 
  Sys.sleep(7) 
}

allNYTSearch <- rbind_pages(pages)


#Segmentation

# Visualize coverage by section
allNYTSearch %>% 
  group_by(response.docs.type_of_material) %>%
  dplyr::summarize(count=n()) %>%
  mutate(percent = (count / sum(count))*100) %>%
  ggplot() +
  geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()

#Make another column of News versus Other ... The labels

allNYTSearch$NewsOrOther = ifelse(allNYTSearch$response.docs.type_of_material == "News","News","Other")
#There is an NA in NewsOrOther

# Visualize coverage of News or Other
allNYTSearch[!is.na(allNYTSearch$NewsOrOther),] %>% 
  group_by(NewsOrOther) %>%
  dplyr::summarize(count=n()) %>%
  mutate(percent = (count / sum(count))*100) %>%
  ggplot() +
  geom_bar(aes(y=percent, x=NewsOrOther, fill=NewsOrOther), stat = "identity") + coord_flip()



#Train and Test Split 70%/30%

set.seed(2)
trainInd = sample(seq(1,dim(allNYTSearch)[1],1),round(.7*dim(allNYTSearch)[1]))
allNYTSearchTrain = allNYTSearch[trainInd,]
allNYTSearchTest = allNYTSearch[-trainInd,]


#This function returns P(News | Keyword) 
#P(News|KW) = P(KW|News)* P(News) / P(KW)
Pnews_word = function(key_word, trainingSet, alphaLaplace = 1, betaLaplace = 1) # alpha and beta are for laplace smoothing
{
  trainingSet$response.docs.headline.main = unlist(str_replace_all(trainingSet$response.docs.headline.main,"[^[:alnum:] ]", "")) #Take out all but alpha numeric characters from training headlines
  
  #print(key_word)
  NewsGroup = trainingSet[trainingSet$NewsOrOther == "News",]
  OtherGroup = trainingSet[trainingSet$NewsOrOther == "Other",]
  
  pNews = dim(NewsGroup)[1] / (dim(NewsGroup)[1] + dim(OtherGroup)[1])
  pOther = 1 - pNews
  
  pKWGivenNews = (length(str_which(NewsGroup$response.docs.headline.main,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))+alphaLaplace)/(dim(NewsGroup)[1]+betaLaplace)
  pKWGivenOther = (length(str_which(OtherGroup$response.docs.headline.main,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))+alphaLaplace)/(dim(OtherGroup)[1]+betaLaplace)
  
  pKW = length(str_which(trainingSet$response.docs.headline.main,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))/dim(trainingSet)[1]
  
  pNewsGivenKW = pKWGivenNews*pNews/pKW
  pOtherGivenKW = pKWGivenOther*pOther/pKW
  
  return(pNewsGivenKW)
}

theScoreHolderNews = c()
theScoreHolderOther = c()
articleScoreNews = 0;
articleScoreOther = 0;


for (i in 1 : dim(allNYTSearchTest)[1])  #This loop iterates over the articles in the Test Set
{
  
  articleScoreNews = 1; 
  articleScoreOther = 1;

#The [^[:alnum:] ] replaces all non alphanumeric characters with nulls.  
theText = unlist(str_split(str_replace_all(allNYTSearchTest[i,]$response.docs.headline.main,"[^[:alnum:] ]", ""), stringr::boundary("word"))) #Take out all but alpha numeric characters from search string ... theText holds each word in the headline as its own word.  

# stopwords() #from package tm
wordsToTakeOut = stopwords()

# put word boundaries stopwords so that we don't detect partial words later
wordsToTakeOut = str_c(wordsToTakeOut,collapse = "\\b|\\b") 
wordsToTakeOut = str_c("\\b",wordsToTakeOut,"\\b")
#wordsToTakeOut

importantWords = theText[!str_detect(theText,regex(wordsToTakeOut,ignore_case = TRUE))]

#importantWords

  for(j in 1 : length(importantWords))  #This loop iterates over the important words in the headline
  {
    articleScoreNews = articleScoreNews * Pnews_word(importantWords[j],allNYTSearchTrain)
    articleScoreOther = articleScoreOther * (1 - Pnews_word(importantWords[j],allNYTSearchTrain))
  }
  theScoreHolderNews[i] = articleScoreNews
  theScoreHolderOther[i] = articleScoreOther
}

# Classify the aricle as News or Other based on a given piece of information from the article.
allNYTSearchTest$Classified = ifelse(theScoreHolderNews > theScoreHolderOther,"News","Other")

#Confusion Matrix
table(allNYTSearchTest$Classified,allNYTSearchTest$NewsOrOther) #Actual in Columns
confusionMatrix(factor(allNYTSearchTest$Classified),factor(allNYTSearchTest$NewsOrOther))

```
##snippet
```{r}
#NYT Example
#headline

library(tm) #text mining library provides the stopwords() function
library(tidyr)
library(plyr)
library(jsonlite)
library(dplyr)
library(tidyverse)
library(XML) #xml_Parse
library(dplyr)
library(tidyr)
library(stringi)
library(rvest) #html_table, html_node
library(ggplot2)
library(RCurl) #getURL
library(class)
library(caret)
library(e1071)

NYTIMES_KEY = "OG89fUubcS8FXofVrLA4dmIOHh5omiFa" #Your Key Here … get from NTY API website

# Let's set some parameters

# Trump Search
term <- "Trump" # Need to use + to string together separate words
begin_date <- "20190415"
end_date <- "20190502"

baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
                  "&begin_date=",begin_date,"&end_date=",end_date,
                  "&facet_filter=true&api-key=",NYTIMES_KEY, sep="")

baseurl

initialQuery <- jsonlite::fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages

pages <- list()
for(i in 0:maxPages){
  nytSearch <- jsonlite::fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame() 
  message("Retrieving page ", i)
  pages[[i+1]] <- nytSearch 
  Sys.sleep(7) 
}

allNYTSearch <- rbind_pages(pages)


#Segmentation

# Visualize coverage by section
allNYTSearch %>% 
  group_by(response.docs.type_of_material) %>%
  dplyr::summarize(count=n()) %>%
  mutate(percent = (count / sum(count))*100) %>%
  ggplot() +
  geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()

#Make another column of News versus Other ... The labels

allNYTSearch$NewsOrOther = ifelse(allNYTSearch$response.docs.type_of_material == "News","News","Other")
#There is an NA in NewsOrOther

# Visualize coverage of News or Other
allNYTSearch[!is.na(allNYTSearch$NewsOrOther),] %>% 
  group_by(NewsOrOther) %>%
  dplyr::summarize(count=n()) %>%
  mutate(percent = (count / sum(count))*100) %>%
  ggplot() +
  geom_bar(aes(y=percent, x=NewsOrOther, fill=NewsOrOther), stat = "identity") + coord_flip()



#Train and Test Split 70%/30%

set.seed(2)
trainInd = sample(seq(1,dim(allNYTSearch)[1],1),round(.7*dim(allNYTSearch)[1]))
allNYTSearchTrain = allNYTSearch[trainInd,]
allNYTSearchTest = allNYTSearch[-trainInd,]


#This function returns P(News | Keyword) 
#P(News|KW) = P(KW|News)* P(News) / P(KW)
Pnews_word = function(key_word, trainingSet, alphaLaplace = 1, betaLaplace = 1) # alpha and beta are for laplace smoothing
{
  trainingSet$response.docs.snippet = unlist(str_replace_all(trainingSet$response.docs.snippet,"[^[:alnum:] ]", "")) #Take out all but alpha numeric characters from training headlines
  
  #print(key_word)
  NewsGroup = trainingSet[trainingSet$NewsOrOther == "News",]
  OtherGroup = trainingSet[trainingSet$NewsOrOther == "Other",]
  
  pNews = dim(NewsGroup)[1] / (dim(NewsGroup)[1] + dim(OtherGroup)[1])
  pOther = 1 - pNews
  
  pKWGivenNews = (length(str_which(NewsGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))+alphaLaplace)/(dim(NewsGroup)[1]+betaLaplace)
  pKWGivenOther = (length(str_which(OtherGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))+alphaLaplace)/(dim(OtherGroup)[1]+betaLaplace)
  
  pKW = length(str_which(trainingSet$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore.case = TRUE)))/dim(trainingSet)[1]
  
  pNewsGivenKW = pKWGivenNews*pNews/pKW
  pOtherGivenKW = pKWGivenOther*pOther/pKW
  
  return(pNewsGivenKW)
}

theScoreHolderNews = c()
theScoreHolderOther = c()
articleScoreNews = 0;
articleScoreOther = 0;


for (i in 1 : dim(allNYTSearchTest)[1])  #This loop iterates over the articles in the Test Set
{
  
  articleScoreNews = 1; 
  articleScoreOther = 1;

#The [^[:alnum:] ] replaces all non alphanumeric characters with nulls.  
theText = unlist(str_split(str_replace_all(allNYTSearchTest[i,]$response.docs.snippet,"[^[:alnum:] ]", ""), stringr::boundary("word"))) #Take out all but alpha numeric characters from search string ... theText holds each word in the headline as its own word.  

# stopwords() #from package tm
wordsToTakeOut = stopwords()

# put word boundaries stopwords so that we don't detect partial words later
wordsToTakeOut = str_c(wordsToTakeOut,collapse = "\\b|\\b") 
wordsToTakeOut = str_c("\\b",wordsToTakeOut,"\\b")
#wordsToTakeOut

importantWords = theText[!str_detect(theText,regex(wordsToTakeOut,ignore_case = TRUE))]

#importantWords

  for(j in 1 : length(importantWords))  #This loop iterates over the important words in the headline
  {
    articleScoreNews = articleScoreNews * Pnews_word(importantWords[j],allNYTSearchTrain)
    articleScoreOther = articleScoreOther * (1 - Pnews_word(importantWords[j],allNYTSearchTrain))
  }
  theScoreHolderNews[i] = articleScoreNews
  theScoreHolderOther[i] = articleScoreOther
}

# Classify the aricle as News or Other based on a given piece of information from the article.
allNYTSearchTest$Classified = ifelse(theScoreHolderNews > theScoreHolderOther,"News","Other")

#Confusion Matrix
table(allNYTSearchTest$Classified,allNYTSearchTest$NewsOrOther) #Actual in Columns
confusionMatrix(factor(allNYTSearchTest$Classified),factor(allNYTSearchTest$NewsOrOther))

```
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```
