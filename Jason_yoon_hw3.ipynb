{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SMU NLP Course—Homework 3\n",
        "Homework 3"
      ],
      "metadata": {
        "id": "jsAMlNp13rzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compare your given name with your nickname (if you don’t have a nickname, invent one for this\n",
        "assignment) by answering the following questions\n",
        "a. What is the edit distance between your nickname and your given name?"
      ],
      "metadata": {
        "id": "rKk56Zu7xKUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(str1, str2):\n",
        "    m = len(str1) + 1\n",
        "    n = len(str2) + 1\n",
        "\n",
        "    # Initialize a matrix to store the edit distances\n",
        "    dp = [[0] * n for _ in range(m)]\n",
        "\n",
        "    # Fill the matrix with base cases\n",
        "    for i in range(m):\n",
        "        dp[i][0] = i\n",
        "\n",
        "    for j in range(n):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill the matrix using dynamic programming\n",
        "    for i in range(1, m):\n",
        "        for j in range(1, n):\n",
        "            cost = 0 if str1[i - 1] == str2[j - 1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + 1,  # Deletion\n",
        "                dp[i][j - 1] + 1,  # Insertion\n",
        "                dp[i - 1][j - 1] + cost  # Substitution\n",
        "            )\n",
        "\n",
        "    return dp[m - 1][n - 1]\n",
        "\n",
        "# Example usage\n",
        "nickname = \"Jason\"\n",
        "given_name = \"Gwonchan\"\n",
        "distance = levenshtein_distance(nickname, given_name)\n",
        "print(f\"Edit distance between '{nickname}' and '{given_name}': {distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOA3dqxWwXYq",
        "outputId": "7726b2ff-8f6d-4efd-9b86-cdbed7ae51dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit distance between 'Jason' and 'Gwonchan': 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. What is the percentage string match between your nickname and your given name? Show your work for both calculations."
      ],
      "metadata": {
        "id": "6Bta4p2pxGtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_percentage_string_match(edit_distance, length_str1, length_str2):\n",
        "    return (1 - edit_distance / max(length_str1, length_str2)) * 100\n",
        "\n",
        "# Edit distance between \"Jason\" and \"Gwonchan\" is 3\n",
        "edit_distance = 3\n",
        "length_jason = len(\"Jason\")\n",
        "length_gwonchan = len(\"Gwonchan\")\n",
        "\n",
        "# Calculate percentage string match\n",
        "percentage_match_jason = calculate_percentage_string_match(edit_distance, length_jason, length_gwonchan)\n",
        "percentage_match_gwonchan = calculate_percentage_string_match(edit_distance, length_gwonchan, length_jason)\n",
        "\n",
        "print(f\"Percentage string match for 'Jason': {percentage_match_jason:.2f}%\")\n",
        "print(f\"Percentage string match for 'Gwonchan': {percentage_match_gwonchan:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzuveiwmxEvZ",
        "outputId": "3b6e8357-d04d-4e04-eedf-de5b3ebad3d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage string match for 'Jason': 62.50%\n",
            "Percentage string match for 'Gwonchan': 62.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words."
      ],
      "metadata": {
        "id": "CbUHtzXcxQB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ANS] I provided \"Lord my shepherd I have all I need\" to my buddy and he guess it is Psalms 23 in Bible. I believe he already knew this verse! \"The Lord is my shepherd; I have all that I need\"\n",
        "Also I provided \"first decade half twenty-first century frustrating time american opinion polls election results attest to exceptional levels pessimism unease\" to my friend and his guess is wrong. These words quoted from \"The Fractured Republic\" by Yuval Levin but he recommend me to read \"The Unwinding: An Inner History of the New America\" by George Packer. I believe he just want to memorize popular books."
      ],
      "metadata": {
        "id": "XsIDhivQxt56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run one of the stemmers available in Python. Run the same two sentences from question 2\n",
        "above through the stemmer and show the results. How many of the outputted stems are valid\n"
      ],
      "metadata": {
        "id": "cy2RM3FGxcMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "#nltk.download('punkt')\n",
        "\n",
        "# Sample text\n",
        "text = \"The Lord is my shepherd; I have all that I need\"\n",
        "text1 = \"The first decade and a half of the twenty-first century has been a frustrating time for americans. Opinion polls and election results attest to exceptional levels of pessimism and unease\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "words1 = word_tokenize(text1)\n",
        "\n",
        "# Initialize the Porter stemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "# Apply Porter stemming to each word\n",
        "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
        "stemmed_words1 = [porter_stemmer.stem(word) for word in words1]\n",
        "\n",
        "# Join the stemmed words back into a sentence\n",
        "stemmed_text = ' '.join(stemmed_words)\n",
        "stemmed_text1 = ' '.join(stemmed_words1)\n",
        "\n",
        "print(\"Original text:\", text)\n",
        "print(\"Stemmed text:\", stemmed_text)\n",
        "\n",
        "print(\"Original text1:\", text1)\n",
        "print(\"Stemmed text1:\", stemmed_text1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGub4eMC2slU",
        "outputId": "9c154140-bfc7-42f8-e71a-5f74ab68826d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: The Lord is my shepherd; I have all that I need\n",
            "Stemmed text: the lord is my shepherd ; i have all that i need\n",
            "Original text1: The first decade and a half of the twenty-first century has been a frustrating time for americans. Opinion polls and election results attest to exceptional levels of pessimism and unease\n",
            "Stemmed text1: the first decad and a half of the twenty-first centuri ha been a frustrat time for american . opinion poll and elect result attest to except level of pessim and uneas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valid stem for text: lord, my, shepherd, I, have, all, I, need (8)\n",
        "valid stem for text1: first, half, twenty-first, time, opinion, result, attest, level (8)"
      ],
      "metadata": {
        "id": "c58_kDqB4cQ-"
      }
    }
  ]
}