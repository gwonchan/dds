
###1.	How many breweries are present in each state



```{r}

hello_breweries = read.csv("Breweries.csv")
hello_beers = read.csv("Beers.csv")
dim(hello_breweries)
head(hello_breweries)
dim(hello_beers)
head(hello_beers)

#by states
hello1=table(hello_breweries$State)
hello1
dim(hello1)
plot(hello1,main = "Breweries by state",xlab = "States", ylab = "# of Breweries",ylim=c(0,60),cex.axis = 1, las=2)
```
##2.	Merge beer data with the breweries data. Print the first 6 observations and the last six observations to check the merged file.  (RMD only, this does not need to be included in the presentation or the deck.)

```{r}
hello_merge = merge(hello_breweries,hello_beers,by.x = "Brew_ID", by.y = "Brewery_id")
dim(hello_merge)
head(hello_merge)
filter(hello_breweries, "Brew_ID" == "1")
filter(hello_beers, "Beer_ID" == "2689")
tail(hello_merge)
filter(hello_breweries, "Brew_ID" == "558")
filter(hello_beers, "Beer_ID" == "30")

```
##3.	Address the missing values in each column.
```{r}
hello_NA = hello_merge[!complete.cases(hello_merge),]
dim(hello_NA)
head(hello_NA)
hello_NNA = hello_merge[complete.cases(hello_merge),]
dim(hello_NNA)
head(hello_NNA)
library(naniar)
gg_miss_var(hello_merge)
```
##4.	Compute the median alcohol content and international bitterness unit for each state. Plot a bar chart to compare.
```{r}
library(dplyr)
dplyr::summarize
hello1 <- hello_merge %>% group_by(State) %>% summarize(medianABV = median(ABV,na.rm = TRUE), count = n()) %>% arrange(medianABV)
print(hello1)
barplot(hello1$medianABV, names.arg = hello1$State, las=2)

hello2 <- hello_merge %>% group_by(State) %>% summarize(medianIBU = median(IBU,na.rm = TRUE), count = n()) %>% arrange(medianIBU)
print(hello2)
barplot(hello2$medianIBU, names.arg = hello2$State, las=2)
```

##5.	Which state has the maximum alcoholic (ABV) beer? Which state has the most bitter (IBU) beer?
```{r}
hello_ABV <- hello_merge %>% group_by(State)%>%summarize(max_alc=max(ABV,na.rm=TRUE)) %>% arrange(desc(max_alc))
hello_IBU <- hello_merge %>% group_by(State)%>%summarize(max_ibu=max(IBU,na.rm=TRUE)) %>% arrange(max_ibu)
hello_ABV
hello_IBU
```
6.	Comment on the summary statistics and distribution of the ABV variable.
```{r}
summary(hello_merge$ABV)
hist(hello_merge$ABV,main = "Histogram of ABV",xlab = "ABV", ylab = "Count")
```
7.	Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot.  Make your best judgment of a relationship and EXPLAIN your answer.
```{r}
library(ggplot2)
hello_merge %>% ggplot(aes(x = ABV, y = IBU)) + 
geom_point(color = "blue")
scatter.smooth(x=hello_merge$ABV, y=hello_merge$IBU, main = "Mild positive linear relationship",xlab = "ABV", ylab = "IBU", col="blue")
print("This data shows mild positive linear relationship between bitterness and alcoholic content(3rd degree polynomial). Most of Beer bitterness comes from hops. ")
```
8.	Budweiser would also like to investigate the difference with respect to IBU and ABV between IPAs (India Pale Ales) and other types of Ale (any beer with “Ale” in its name other than IPA).  You decide to use KNN classification to investigate this relationship.  Provide statistical evidence one way or the other. You can of course assume your audience is comfortable with percentages … KNN is very easy to understand conceptually. 
In addition, while you have decided to use KNN to investigate this relationship (KNN is required) you may also feel free to supplement your response to this question with any other methods or techniques you have learned.  Creativity and alternative solutions are always encouraged.  
```{r}
library(XML) #xml_Parse
library(dplyr)
library(tidyr)
library(stringi)
library(rvest) #html_table, html_node
library(ggplot2)
library(RCurl) #getURL
library(class)
library(caret)
library(e1071)
#install.packages("Hmisc")
library(Hmisc)
#install.packages("stringr")     # Install & load stringr package
library("stringr")
library(naniar)

#classfy IPAs or not, using IBU and ABV values.
#make new column as IPAs and the values will be 1 or 0. When the Style has "IPA", the value will be 1. nor 0.
#hello_IPA <- 1*str_detect(hello_merge$Style, "IPA")
hello_IPAs = ifelse(str_detect(hello_merge$Style,"IPA")==TRUE,"IPA",ifelse(str_detect(hello_merge$Style,"Ale")==TRUE,"ALE","Other"))
hello_IPAs
hello_merge$Beer_type <- hello_IPAs
head(hello_merge)


hello_merge %>% ggplot(aes(x = ABV, y = IBU, color=Beer_type)) + 
geom_point() +
stat_ellipse()

#median IPA
hello_filter1=filter(hello_merge, Beer_type == "IPA")
median(hello_filter1$ABV[which(!is.na(hello_filter1$ABV))])
median(hello_filter1$IBU[which(!is.na(hello_filter1$IBU))])

#median Ale
hello_filter2=filter(hello_merge, Beer_type == "ALE")
median(hello_filter2$ABV[which(!is.na(hello_filter2$ABV))])
median(hello_filter2$IBU[which(!is.na(hello_filter2$IBU))])

#median no IPA
hello_filter3=filter(hello_merge, Beer_type == "Other")
median(hello_filter3$ABV[which(!is.na(hello_filter3$ABV))])
median(hello_filter3$IBU[which(!is.na(hello_filter3$IBU))])


#impute missing values with median
hello_impute <- hello_merge
hello_impute$IBU <- impute(hello_impute$IBU, median)
hello_impute$ABV <- impute(hello_impute$ABV, median)
hello_impute = hello_impute[complete.cases(hello_impute),]
gg_miss_var(hello_impute)

#scaling
hello_scale = hello_impute
hello_scale$IBU = scale(hello_impute$IBU)
hello_scale$ABV = scale(hello_impute$ABV)
hello_scale %>% ggplot(aes(x = ABV, y = IBU, color=Beer_type)) + 
geom_point() +
stat_ellipse()
```

```{r}
#70/30 training/
# Loop for many k and the average of many training / test partition

set.seed(100)
iterations = 10
numks = 20
splitPerc = .70

masterAcc = matrix(nrow = iterations, ncol = numks)


for(j in 1:iterations)
{
  trainIndices = sample(1:dim(hello_scale)[1],round(splitPerc * dim(hello_scale)[1]))
  train = hello_scale[trainIndices,]
  test = hello_scale[-trainIndices,]
  for(i in 1:numks)
  {
    classifications = knn(train[,c(7,8)],test[,c(7,8)],train$Beer_type, prob = TRUE, k = i)
    table(classifications,test$Beer_type)
    CM = confusionMatrix(table(classifications,test$Beer_type))
    masterAcc[j,i] = CM$overall[1]
  }
  
}

MeanAcc = colMeans(masterAcc)

plot(seq(1,numks,1),MeanAcc, type = "l")

which.max(MeanAcc)
max(MeanAcc)
```

```{r}
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 20.
classifications = knn(train[,c(7,8)],test[,c(7,8)],train$Beer_type, prob = TRUE, k = 5)
table(classifications,test$Beer_type)
CM = confusionMatrix(table(classifications,test$Beer_type))
CM
```
```{r}
#decision boundary
prob1 <- attr(classifications, "prob")
px1 <- test$ABV
px2 <- test$IBU


mat = matrix(, nrow = 723, ncol = 3)
mat[,1] <- px1
mat[,2] <- px2
mat[,3] <- classifications

dff <- data.frame(mat)
colnames(dff) <- c('var1', 'var2', 'var3')

ggplot(dff)+geom_point(aes(x = var1, y = var2, col=var3))+
geom_contour(aes(x = var1, y = var2, z = var3))
```

```{r}
#input
biterness = 100
alchol = 0.089

#scale
scaled_center_biterness = 39.49668
scaled_scale_biterness = 20.17576
scaled_center_alc = 0.05967635
scaled_scale_alc = 0.01337969

y=(biterness-scaled_center_biterness)/scaled_scale_biterness
x=(alchol-scaled_center_alc)/scaled_scale_alc
test1= c(x,y)
knn(train[,c(7,8)],test1,train$Beer_type, prob = TRUE, k = 5)

```


library(tidyverse)
library(caret)
library(e1071)
library(class)

hello_breweries = read.csv("Breweries.csv")
hello_beers = read.csv("Beers.csv")
merged = merge(hello_breweries,hello_beers,by.x = "Brew_ID", by.y = "Brewery_id")
nrow(merged)
names(merged)
merged <- merged %>% filter(!is.na(ABV) & !is.na(IBU))
merged$Style

# Creating IPA dataset
#IPA1 <- which(str_detect(merged$Style, 'India Pale Ale'))
IPA2 <- which(str_detect(merged$Style, 'IPA'))
#IPA1 %in% IPA2, IPA2 has everything IPA1 has
length(IPA2)
#nrow(merged[c(which(str_detect(merged$Style, 'India Pale Ale')), which(str_detect(merged$Style, 'IPA'))),]) #Got IPA
IPA_beers <- merged[IPA2,]
nrow(IPA_beers)
head(IPA_beers)

# Creating Ale dataset
sum(str_detect(merged$Style, 'Ale'))
#so should have 552 since 559 have Ale and only 7 had India Pale Ale
sum(which(str_detect(merged$Style, 'Ale')) %in% IPA2)
which(which(str_detect(merged$Style, 'Ale')) %in% IPA2)
# there were 7 overlaps
Ale_beers <- merged[which(str_detect(merged$Style, 'Ale')),]
Ale_beers <- Ale_beers[-which(which(str_detect(merged$Style, 'Ale')) %in% IPA2),]
nrow(Ale_beers)


# extracting row numbers and only selecting those rows
# then changing names to simply Ale or IPA
as.integer(rownames(Ale_beers))
as.integer(rownames(IPA_beers))
IPA_and_Ale <- merged[c(as.integer(rownames(Ale_beers)), as.integer(rownames(IPA_beers))),]
IPA_and_Ale$Style <- ifelse(IPA_and_Ale$Style %in% Ale_beers$Style, 'Ale', 'IPA')
nrow(IPA_and_Ale) # 944 rows

# time for classification
set.seed(5)
trainIndices_IPA_and_Ale = sample(seq(1:length(IPA_and_Ale$Style)),round(.7*length(IPA_and_Ale$Style)))
length(trainIndices_IPA_and_Ale)
train_IPA_and_Ale = IPA_and_Ale[trainIndices_IPA_and_Ale,]
test_IPA_and_Ale = IPA_and_Ale[-trainIndices_IPA_and_Ale,]
nrow(train_IPA_and_Ale) # 661 in train set
nrow(test_IPA_and_Ale) # 283 in test set
names(train_IPA_and_Ale) # ABV is 7th column, IBu 8, Style 9


# Find best working KNN
iterations = 10
numks = 30

masterAcc = matrix(nrow = iterations, ncol = numks)
masterSens = matrix(nrow = iterations, ncol = numks)
masterSpec = matrix(nrow = iterations, ncol = numks)


# realized I need to standardize my variables
summary(IPA_and_Ale$IBU)
summary(IPA_and_Ale$ABV)
IPA_and_Ale$ABV <- scale(IPA_and_Ale$ABV)
IPA_and_Ale$IBU <- scale(IPA_and_Ale$IBU)
str(IPA_and_Ale)
IPA_and_Ale$IBU <- as.numeric(IPA_and_Ale$IBU)
IPA_and_Ale$ABV <- as.numeric(IPA_and_Ale$ABV)
#knn

set.seed(2)
for(j in 1:iterations)
{
  trainIndices_IPA_and_Ale = sample(seq(1:length(IPA_and_Ale$Style)),round(.7*length(IPA_and_Ale$Style)))
  train_IPA_and_Ale = IPA_and_Ale[trainIndices_IPA_and_Ale,]
  test_IPA_and_Ale = IPA_and_Ale[-trainIndices_IPA_and_Ale,]

  for(i in 1:numks)
  {
    classifications = knn(train_IPA_and_Ale[,c(7,8)],test_IPA_and_Ale[,c(7,8)], train_IPA_and_Ale$Style,k = i)
    CM = confusionMatrix(table(classifications,test_IPA_and_Ale$Style))
    masterAcc[j,i] = CM$overall[1]
    masterSens[j,i] = CM$byClass[1]
    masterSpec[j,i] = CM$byClass[2]
  }
}

MeanAcc = colMeans(masterAcc)
MeanSens = colMeans(masterSens)
MeanSpec = colMeans(masterSpec)
MeanAcc
MeanSens
MeanSpec
plot(seq(1,numks,1),MeanAcc, type = "l")
which.max(MeanAcc)
unique(merged$Style)
#KNN
classifications = knn(trainTitanic[,c(3,6)],trainTitanic[,c(3,6)],as.factor(trainTitanic$Survived), prob = TRUE, k = 3)
table(as.factor(trainTitanic$Survived),classifications)
CM_KNN = confusionMatrix(table(as.factor(trainTitanic$Survived),classifications))
##9.	Knock their socks off!  Find one other useful inference from the data that you feel Budweiser may be able to find value in.  You must convince them why it is important and back up your conviction with appropriate statistical evidence. 
```{r}
##market share, beers by breweries
freq_table=table(hello_merge$Name.x)
plot(freq_table,main = "Breweries by competitors",xlab = "Names", ylab = "# of Breweries",ylim=c(0,50),cex.axis = 1, las=2)
#top three
hello_market <- hello_merge %>% group_by(Name.x)%>%tally(sort = TRUE)
#add state on column
hello_market <- as.data.frame(hello_market)
df1 = Breweries %>% select(Name,State)
df2 = merge(hello_market,df1,by.x = "Name.x",by.y = "Name")%>% arrange(desc(n))
#which is the best state to sell IPA?
#what is the best, optimized ABV and IBU in Texas market?

```